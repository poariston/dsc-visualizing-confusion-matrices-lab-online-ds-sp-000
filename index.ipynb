{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Confusion Matrices - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll build upon the previous lesson on confusion matrices and visualize a confusion matrix using `matplotlib`. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab you will:  \n",
    "\n",
    "- Create a confusion matrix from scratch \n",
    "- Create a confusion matrix using scikit-learn \n",
    "- Craft functions that visualize confusion matrices \n",
    "\n",
    "## Confusion matrices\n",
    "\n",
    "Recall that the confusion matrix represents the counts (or normalized counts) of our True Positives, False Positives, True Negatives, and False Negatives. This can further be visualized when analyzing the effectiveness of our classification algorithm.   \n",
    "  \n",
    "Here's an example of how a confusion matrix is displayed:\n",
    "<img src=\"./images/new_confusion_matrix_2.png\" width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, let's look at some code for generating this kind of visual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our model\n",
    "As usual, we start by fitting a model to data by importing, normalizing, splitting into train and test sets and then calling your chosen algorithm. All you need to do is run the following cell. The code should be familiar to you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1000000000000.0, class_weight=None, dual=False,\n",
      "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481132</td>\n",
       "      <td>0.244292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.603053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.283105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.251142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.816794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  sex        cp  trestbps      chol  fbs  restecg   thalach  exang  \\\n",
       "0  0.708333  1.0  1.000000  0.481132  0.244292  1.0      0.0  0.603053    0.0   \n",
       "1  0.166667  1.0  0.666667  0.339623  0.283105  0.0      0.5  0.885496    0.0   \n",
       "2  0.250000  0.0  0.333333  0.339623  0.178082  0.0      0.0  0.770992    0.0   \n",
       "3  0.562500  1.0  0.333333  0.245283  0.251142  0.0      0.5  0.816794    0.0   \n",
       "4  0.583333  0.0  0.000000  0.245283  0.520548  0.0      0.5  0.702290    1.0   \n",
       "\n",
       "    oldpeak  slope   ca      thal  target  \n",
       "0  0.370968    0.0  0.0  0.333333     1.0  \n",
       "1  0.564516    0.0  0.0  0.666667     1.0  \n",
       "2  0.225806    1.0  0.0  0.666667     1.0  \n",
       "3  0.129032    1.0  0.0  0.666667     1.0  \n",
       "4  0.096774    1.0  0.0  0.666667     1.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Define appropriate X and y\n",
    "X = df[df.columns[:-1]]\n",
    "y = df.target\n",
    "\n",
    "# Normalize the data\n",
    "for col in df.columns:\n",
    "    df[col] = (df[col] - min(df[col]))/ (max(df[col]) - min(df[col]))\n",
    "\n",
    "# Split the data into train and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Fit a model\n",
    "logreg = LogisticRegression(fit_intercept=False, C=1e12, solver='liblinear')\n",
    "model_log = logreg.fit(X_train, y_train)\n",
    "\n",
    "# Preview model params\n",
    "print(model_log) \n",
    "\n",
    "# Predict\n",
    "y_hat_test = logreg.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "# Data preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1000000000000.0, class_weight=None, dual=False,\n",
      "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(model_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225    0\n",
       " 152    1\n",
       " 228    0\n",
       " 201    0\n",
       " 52     1\n",
       "       ..\n",
       " 46     1\n",
       " 160    1\n",
       " 232    0\n",
       " 181    0\n",
       " 27     1\n",
       " Name: target, Length: 76, dtype: int64, pandas.core.series.Series)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test,type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.series.Series, numpy.ndarray)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test),type(y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225    0\n",
       "152    3\n",
       "228    2\n",
       "201    0\n",
       "52     1\n",
       "      ..\n",
       "46     3\n",
       "160    3\n",
       "232    0\n",
       "181    0\n",
       "27     3\n",
       "Name: target, Length: 76, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test+2*y_hat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test+2*y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "3    39\n",
      "0    24\n",
      "2     9\n",
      "1     4\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(type((y_test+2*y_hat_test).value_counts()))\n",
    "print((y_test+2*y_hat_test).value_counts())\n",
    "t=((y_test+2*y_hat_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 39, 0: 24, 2: 9, 1: 4}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the confusion matrix\n",
    "\n",
    "To gain a better understanding of confusion matrices, complete the `conf_matrix()` function in the cell below.  This function should:\n",
    "\n",
    "* Take in two arguments: \n",
    "    * `y_true`, an array of labels\n",
    "    * `y_pred`, an array of model predictions\n",
    "* Return a confusion matrix in the form of a dictionary, where the keys are `'TP', 'TN', 'FP', 'FN'`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225    0\n",
       "152    3\n",
       "228    2\n",
       "201    0\n",
       "52     1\n",
       "      ..\n",
       "46     3\n",
       "160    3\n",
       "232    0\n",
       "181    0\n",
       "27     3\n",
       "Name: target, Length: 76, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    #create an empty dictionary\n",
    "confmatdic={}\n",
    "t=y_test+2*y_hat_test\n",
    "t\n",
    "    # calculate TP : y_true=1, y_pred=1, t=4\n",
    "    # calculate TN: y_true=0,y_pred=0, t= 0\n",
    "    # calculate FP: y_true=0 ,y_pred=1, t=2\n",
    "    # calculate FN: y_true=1,y_pred=0, t=1\n",
    "# confmatdic=dict(t)\n",
    "    #return confusion matrix dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 39, 0: 24, 2: 9, 1: 4}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conf_matrix(y_true, y_pred):\n",
    "    #create an empty dictionary\n",
    "    confmatdic={}\n",
    "    t=y_true+2*y_pred\n",
    "    # calculate TP : y_true=1, y_pred=1, t=4\n",
    "    # calculate TN: y_true=0,y_pred=0, t= 0\n",
    "    # calculate FP: y_true=0 ,y_pred=1, t=2\n",
    "    # calculate FN: y_true=1,y_pred=0, t=1\n",
    "    confmatdic=dict(t.value_counts())\n",
    "    #return confusion matrix dictionary\n",
    "    return confmatdic\n",
    "\n",
    "\n",
    "\n",
    "# Test the function\n",
    "conf_matrix(y_test, y_hat_test)\n",
    "# Expected output: {'TP': 39, 'TN': 24, 'FP': 9, 'FN': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check your work with `sklearn`\n",
    "\n",
    "To check your work, make use of the `confusion_matrix()` function found in `sklearn.metrics` and make sure that `sklearn`'s results match up with your own from above.\n",
    "\n",
    "- Import the `confusion_matrix()` function\n",
    "- Use it to create a confusion matrix for `y_test` versus `y_hat_test`, as above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import confusion_matrix\n",
    "\n",
    "\n",
    "# Print confusion matrix\n",
    "cnf_matrix = None\n",
    "print('Confusion Matrix:\\n', cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a nice visual\n",
    "\n",
    "Creating a pretty visual is a little more complicated. Generating the initial image is simple but you'll have to use the `itertools` package to iterate over the matrix and append labels to the individual cells. In this example, `cnf_matrix` is the result of the scikit-learn implementation of a confusion matrix from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Create the basic matrix\n",
    "plt.imshow(cnf_matrix,  cmap=plt.cm.Blues) \n",
    "\n",
    "# Add title and axis labels\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "# Add appropriate axis scales\n",
    "class_names = set(y) # Get class labels to add to matrix\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Add labels to each cell\n",
    "thresh = cnf_matrix.max() / 2. # Used for text coloring below\n",
    "# Here we iterate through the confusion matrix and append labels to our visualization \n",
    "for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "        plt.text(j, i, cnf_matrix[i, j],\n",
    "                 horizontalalignment='center',\n",
    "                 color='white' if cnf_matrix[i, j] > thresh else 'black')\n",
    "\n",
    "# Add a legend\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a general function that plots the confusion matrix\n",
    "Generalize the above code into a function that you can reuse to create confusion matrix visuals going forward: \n",
    "\n",
    "- `cm`: confusion matrix\n",
    "- `classes`: the class labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    # Pseudocode/Outline:\n",
    "    # Print the confusion matrix (optional)\n",
    "    # Create the basic matrix\n",
    "    # Add title and axis labels\n",
    "    # Add appropriate axis scales\n",
    "    # Add labels to each cell\n",
    "    # Add a legend\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update your function to include an option for normalization \n",
    "When the normalization parameter is set to `True`, your function should return percentages for each class label in the visual rather than raw counts: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    # Check if normalize is set to True\n",
    "    # If so, normalize the raw confusion matrix before visualizing\n",
    "    \n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, cmap=cmap)\n",
    "    \n",
    "    # Add title and axis labels \n",
    "    plt.title('Confusion Matrix') \n",
    "    plt.ylabel('True label') \n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    # Add appropriate axis scales\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    # Text formatting\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    # Add labels to each cell\n",
    "    thresh = cm.max() / 2.\n",
    "    # Here we iterate through the confusion matrix and append labels to our visualization \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment='center',\n",
    "                 color='white' if cm[i, j] > thresh else 'black')\n",
    "    \n",
    "    # Add a legend\n",
    "    plt.colorbar()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a normalized confusion matrix\n",
    "\n",
    "Call the function to visualize a normalized confusion matrix for `cnf_matrix`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a normalized confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Well done! In this lab, you created a confusion matrix from scratch and honed your `matplotlib` skills by visualizing confusion matrices! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
